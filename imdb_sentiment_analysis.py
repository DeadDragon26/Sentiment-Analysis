# -*- coding: utf-8 -*-
"""IMDB_sentiment_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rVtGXUh80kdz2UJNRFFtfrHu7zSeJPf2
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from nltk.corpus import stopwords
import re
from bs4 import BeautifulSoup
import nltk

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

data = pd.read_csv("/content/IMDB Dataset.csv")
df = pd.DataFrame(data)
print(df.head(5))
print(df['sentiment'].value_counts())

def clean_text(text):

    text = BeautifulSoup(text, "html.parser").get_text()

    text = re.sub(r'[^a-zA-Z\s]', ' ', text).lower()

    text = ' '.join([word for word in text.split() if word not in stop_words])
    return text

df['cleaned_review'] = df['review'].apply(clean_text).apply(lambda x: x[:])
df

df.columns

df.iloc[0,0]

len(df.iloc[0,-1])

label_encoder = LabelEncoder()
df['sentiment'] = label_encoder.fit_transform(df['sentiment'])
df

df['sentiment'].value_counts()

tokenizer = Tokenizer(num_words=10000)
tokenizer.fit_on_texts(df['cleaned_review'])
sequences = tokenizer.texts_to_sequences(df['cleaned_review'])

len(sequences[1])

X = pad_sequences(sequences, maxlen=100, padding='post')
X[0]

len(X[19])

y = df['sentiment']
# y

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from tensorflow.keras.layers import LSTM , Bidirectional , Dropout , Dense , Embedding
from tensorflow.keras.models import Sequential


model_lstm = Sequential([
    Embedding(input_dim=10000, output_dim=32, input_length=100),
    LSTM(32, return_sequences=False),
    Dense(64, activation='relu'),
    # Dropout(0.5),
    Dense(2, activation='sigmoid')
])

model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model_lstm.fit(X_train, y_train, epochs=2, validation_data=(X_test, y_test))

text123 = clean_text("very nice and intresting movie")
text123 = df.iloc[3,-1]
text123

'and' in stop_words

tokenize_text =  tokenizer.texts_to_sequences([text123])
input_data = pad_sequences(tokenize_text, maxlen=100, padding='post')
# label_encoder.inverse_transform([np.argmax(model_lstm.predict(input_data))])





prediction = (model_lstm.predict(input_data) > 0.5).astype(int)
sentiment = label_encoder.inverse_transform(prediction.flatten())
print("Predicted Sentiment:", sentiment[0])

le_dict = {0:'Positive',1:'Negative'}

le_dict[sentiment[0]]

def predict(text):
  text = clean_text(i)
  tokenize_text =  tokenizer.texts_to_sequences([text])
  input_data = pad_sequences(tokenize_text, maxlen=100, padding='post')
  prediction = (model_lstm.predict(input_data) > 0.5).astype(int)
  sentiment = label_encoder.inverse_transform(prediction.flatten())
  return le_dict[sentiment[0]]

df

for j,i in enumerate(df.iloc[:,-1][:10]):
  print(le_dict[df['sentiment'][j]],predict(i))

print(df['sentiment'][j])

predict("very nice and intresting movie, the movie was awesome and i will definitely recommend it to others, very good to see")

